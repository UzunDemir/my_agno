# 1. –ê–ë–°–û–õ–Æ–¢–ù–û –ü–ï–†–í–ê–Ø –ö–û–ú–ê–ù–î–ê –í –§–ê–ô–õ–ï - –î–û –õ–Æ–ë–´–• –ò–ú–ü–û–†–¢–û–í!
import streamlit as st
st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ –∞–∫—Ü–∏–π", layout="wide")

# 2. –û—Å–Ω–æ–≤–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã (–ø–æ—Å–ª–µ set_page_config)
from agno.agent import Agent
from agno.models.deepseek import DeepSeek
from agno.tools.reasoning import ReasoningTools
from agno.tools.yfinance import YFinanceTools

# 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞ (—Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º)
@st.cache_resource
def init_agent():
    return Agent(
        model=DeepSeek(id="deepseek-chat"),
        tools=[
            ReasoningTools(add_instructions=True),
            YFinanceTools(
                stock_price=True,
                analyst_recommendations=True,
                company_info=True,
                company_news=True,
            ),
        ],
        instructions=[
            "Use tables to display data.",
            "Include sources in your response.",
            "Only include the report in your response. No other text.",
        ],
        markdown=True,
    )

# 4. –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
def main():
    st.title("üìà –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π")
    
    with st.form("query_form"):
        query = st.text_area(
            "–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å:",
            value="–í—ã–≤–µ–¥–∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏, –æ–±—ä—è—Å–Ω–∏ –ø–æ—á–µ–º—É. –ö–∞–∫–∏–µ –ø—Ä–æ–≥–Ω–æ–∑—ã? –ß—Ç–æ –ø–æ–∫—É–ø–∞—Ç—å/–ø—Ä–æ–¥–∞–≤–∞—Ç—å?",
            height=100
        )
        submitted = st.form_submit_button("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å")
    
    if submitted:
        agent = init_agent()
        
        with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ..."):
            with st.expander("–î–µ—Ç–∞–ª–∏ –∞–Ω–∞–ª–∏–∑–∞", expanded=False):
                reasoning = st.empty()
            
            result = st.empty()
            
            full_response = ""
            for chunk in agent.stream_response(
                query,
                stream=True,
                show_full_reasoning=True,
                stream_intermediate_steps=True
            ):
                if 'reasoning' in chunk:
                    reasoning.markdown(chunk['reasoning'])
                if 'response' in chunk:
                    full_response += chunk['response']
                    result.markdown(full_response)

if __name__ == "__main__":
    main()
